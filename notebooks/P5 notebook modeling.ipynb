{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd580fa2-7960-40f5-af41-33b1b987f3d4",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82baa25d-bbe4-4a18-a788-8920f536ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE, trustworthiness\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer, InterclusterDistance\n",
    "\n",
    "# Set-up environment\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\")\n",
    "os.chdir('/Users/nataschajademinnitt/Documents/5. Data Analysis/segmenting_customers/')\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e70eb-3521-444e-a8fb-d19f03546bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"./data/processed/processed_database.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826af12-cefe-4562-8127-ef3f52890629",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6da4e8-af69-4c0d-9c65-d097d652c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_sets(\n",
    "    df,\n",
    "    dict_features,\n",
    "    scaler,\n",
    "    k_min: int = 2,\n",
    "    k_max: int = 10,\n",
    "    random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses a dictionary of features to find the best k elbow.\n",
    "    Computes silhouette, calinski_harabasz and davies_bouldin at that k.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for name, cols in dict_features.items():\n",
    "        X = df[cols].values\n",
    "        \n",
    "        # use the passed‑in scaler\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # find the elbow\n",
    "        model = KMeans(random_state=random_state)\n",
    "        viz = KElbowVisualizer(\n",
    "            model,\n",
    "            k=(k_min, k_max),\n",
    "            metric='distortion',\n",
    "            show=False,\n",
    "            timings=False\n",
    "        )\n",
    "        viz.fit(X_scaled)\n",
    "        best_k = viz.elbow_value_\n",
    "        \n",
    "        # compute internal scores\n",
    "        labels = KMeans(n_clusters=best_k, random_state=random_state).fit_predict(X_scaled)\n",
    "        sil = silhouette_score(X_scaled, labels)\n",
    "        ch  = calinski_harabasz_score(X_scaled, labels)\n",
    "        db  = davies_bouldin_score(X_scaled, labels)\n",
    "        \n",
    "        results.append({\n",
    "            'feature_set': name,\n",
    "            'scaler': scaler.__class__.__name__,\n",
    "            'best_k_elbow': best_k,\n",
    "            'silhouette_score': sil,\n",
    "            'calinski_harabasz_score': ch,\n",
    "            'davies_bouldin_score': db\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e16e1e-ff79-4443-9967-8d9167a8a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(\n",
    "    data,\n",
    "    feature_cols=None,\n",
    "    metric=\"distortion\",\n",
    "    k_min=2,\n",
    "    k_max=10,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate clustering (elbow, silhouette, intercluster distance) for a set of features.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # 2) Subset & scale once\n",
    "    X = data[feature_cols].values\n",
    "    scaler = RobustScaler().fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    # 3) Make your 3‑panel canvas\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(6, 10))\n",
    "\n",
    "    # Elbow\n",
    "    kelbow = KElbowVisualizer(\n",
    "        KMeans(random_state=random_state),\n",
    "        k=(k_min, k_max),\n",
    "        metric=metric,\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    kelbow.fit(X_scaled)\n",
    "    best_k = kelbow.elbow_value_\n",
    "    kelbow.finalize()\n",
    "\n",
    "    # Silhouette\n",
    "    silvis = SilhouetteVisualizer(\n",
    "        KMeans(n_clusters=best_k, random_state=random_state),\n",
    "        ax=axes[1]\n",
    "    )\n",
    "    silvis.fit(X_scaled)\n",
    "    silvis.finalize()\n",
    "\n",
    "    # Inter‑cluster distances\n",
    "    icd = InterclusterDistance(\n",
    "        KMeans(n_clusters=best_k, random_state=random_state),\n",
    "        ax=axes[2]\n",
    "    )\n",
    "    icd.fit(X_scaled)\n",
    "    icd.finalize()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return best_k, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644b07d-d770-4023-8244-12d878ed1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_radar(df, title=\"Cluster Radar Plot\"):\n",
    "    \"\"\"\n",
    "    Create a radar (spider) plot for cluster profiles.\n",
    "    \"\"\"\n",
    "    # Number of variables\n",
    "    features = df.columns.tolist()\n",
    "    num_vars = len(features)\n",
    "\n",
    "    # Compute angles for each axis\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # complete the loop\n",
    "\n",
    "    # Setup polar plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Plot each cluster\n",
    "    for idx, row in df.iterrows():\n",
    "        values = row.values.flatten().tolist()\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, linewidth=2, label=str(idx))\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    # Add feature labels on the axes\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(features)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6b5cc-c63d-4e39-a6eb-575db1bea3e5",
   "metadata": {},
   "source": [
    "## K-Means segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf278b-cd78-479d-b40e-ade32bd6008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep & scaling\n",
    "features = ['recency','f_returning','m_price_log','s_review_score']\n",
    "X = df[features].values\n",
    "X_scaled = RobustScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54184535-c8eb-421d-95cb-5869dae6a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3, 6):\n",
    "    labels = KMeans(n_clusters=k, random_state=42).fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    ch  = calinski_harabasz_score(X_scaled, labels)\n",
    "    db  = davies_bouldin_score(X_scaled, labels)\n",
    "    print(f\"k={k}: silhouette={sil:.3f}, CH={ch:.1f}, DB={db:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04beade5-e9fe-4189-87ba-77ae0870fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 12))\n",
    "\n",
    "# 3. Elbow visualizer\n",
    "kelbow = KElbowVisualizer(\n",
    "    KMeans(random_state=42),\n",
    "    k=(2,10),\n",
    "    metric='distortion',\n",
    "    ax=axes[0]\n",
    ")\n",
    "kelbow.fit(X_scaled)\n",
    "kelbow.finalize()\n",
    "\n",
    "# 4. Silhouette visualizer (using best_k from elbow)\n",
    "best_k = kelbow.elbow_value_\n",
    "silvis = SilhouetteVisualizer(\n",
    "    KMeans(n_clusters=best_k, random_state=42),\n",
    "    ax=axes[1]\n",
    ")\n",
    "silvis.fit(X_scaled)\n",
    "silvis.finalize()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde5ed0-8cc8-42b2-b5f5-9ee38656d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=4, random_state=42).fit(X_scaled)\n",
    "df['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c18684-edcc-4011-9d44-2c123b16c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['cluster'].value_counts().sort_index()\n",
    "print(pd.DataFrame({'cluster':counts.index, 'count':counts.values}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63faf5e5-9985-4117-a51f-9fe8ceb49c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = TSNE(\n",
    "    perplexity=50,\n",
    "    init='pca',\n",
    "    random_state=42\n",
    ").fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02887f-bd76-429e-bd8e-5822b438098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume Y is your t-SNE embedding of the same samples\n",
    "fig = px.scatter(\n",
    "    x=Y[:,0], y=Y[:,1],\n",
    "    color=df['cluster'].astype(str),\n",
    "    title=\"t-SNE of 4 Clusters\",\n",
    "    labels={'color':'Cluster'}\n",
    ")\n",
    "fig.write_image(f\"plots/tsne_kmeans.png\", width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6271d-12d4-4b68-9258-9627173b1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "for col in features:\n",
    "    fig = px.scatter(\n",
    "        x=Y[:, 0],\n",
    "        y=Y[:, 1],\n",
    "        color=df[col],\n",
    "        color_continuous_scale='Viridis',\n",
    "        title=f\"t-SNE of Customers colored by {col}\",\n",
    "        labels={'x': 't-SNE 1', 'y': 't-SNE 2', 'color': col}\n",
    "    )\n",
    "    fig.write_image(f\"plots/tsne_{col}.png\", width=800, height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1a3da-64c2-4ab3-990a-cc85c9c82f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['recency', 'f_returning', 'm_price', 's_review_score']:\n",
    "    fig = px.violin(\n",
    "        df, x='cluster', y=feature, points=False,\n",
    "        title=f\"Distribution of {feature} by cluster\"\n",
    "    )\n",
    "    fig.write_image(f\"plots/violin_{feature}.png\", width=800, height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242929e-de0a-45e0-ab8f-e236fb9a8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# --- 1. Prepare your data split into time windows ---\n",
    "# Suppose df has a Date column and your features+scale come from df\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Define your windows, e.g. monthly\n",
    "start = df['date'].min()\n",
    "windows = []\n",
    "for i in range(6):   # say you want 6 months of monitoring\n",
    "    t0 = start + pd.DateOffset(months=i)\n",
    "    t1 = t0 + pd.DateOffset(months=1)\n",
    "    windows.append(df[(df['date'] >= t0) & (df['date'] < t1)])\n",
    "    \n",
    "# --- 2. Define your candidate feature subsets ---\n",
    "candidates = [\n",
    "    ['recency','f_returning','m_price_log','s_review_score'],   # rfms\n",
    "    ['recency','f_returning','m_price_log','s_review_score','s_delivery_diff_binary'],  # rfmss\n",
    "    # add any other combos you want to test\n",
    "]\n",
    "\n",
    "random_state = 42\n",
    "K = 4    # fixed number of clusters\n",
    "\n",
    "results = []\n",
    "\n",
    "for feat_set in candidates:\n",
    "    # 3A. Baseline clustering on window 0\n",
    "    X0 = windows[0][feat_set].values\n",
    "    X0s = RobustScaler().fit_transform(X0)\n",
    "    labels0 = KMeans(n_clusters=K, random_state=random_state).fit_predict(X0s)\n",
    "    \n",
    "    # 3B. Step through future windows until ARI < 0.8\n",
    "    survival = 0\n",
    "    for w in windows[1:]:\n",
    "        Xi = w[feat_set].values\n",
    "        if len(Xi) < K: \n",
    "            break   # not enough points to cluster\n",
    "        Xi_s = RobustScaler().fit_transform(Xi)  # or reuse scaler? up to you\n",
    "        li = KMeans(n_clusters=K, random_state=random_state).fit_predict(Xi_s)\n",
    "        ari = adjusted_rand_score(labels0, li)\n",
    "        if ari >= 0.8:\n",
    "            survival += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    results.append({\n",
    "        'features': feat_set,\n",
    "        'survival_months': survival\n",
    "    })\n",
    "\n",
    "# 4. Rank & display\n",
    "res_df = pd.DataFrame(results).sort_values('survival_months', ascending=False)\n",
    "print(res_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3b609-1a6c-4a8a-981a-72a3ff94ae76",
   "metadata": {},
   "source": [
    "## 3. Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de89398-1a9a-4a76-b21f-e0afd01c8e14",
   "metadata": {},
   "source": [
    "### 3.1. K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d8012-f4d8-4f79-b84b-b41b77fff43f",
   "metadata": {},
   "source": [
    "#### Baseline Performance\n",
    "\n",
    "Comaring the baseline performance of k-means clustering for feature combinations using different sclaers: MinMax, Standard, Robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b670d-96d6-4d65-aab0-71a22d49d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_features = {\n",
    "    # 1) RFM baseline\n",
    "    'rfm': ['recency', 'f_returning', 'm_price_log'],\n",
    "\n",
    "    # 2) RFM + s_review_score\n",
    "    'rfm_score': ['recency', 'f_returning', 'm_price_log', 's_review_score'],\n",
    "\n",
    "    # 3) RFM + s_delivery_diff_binary\n",
    "    'rfm_deliv': ['recency', 'f_returning', 'm_price_log', 's_delivery_diff_binary'],\n",
    "    \n",
    "    # 4) RFM + m_pct_freight\n",
    "    'rfm_freight': ['recency', 'f_returning', 'm_price_log', 'm_pct_freight'],\n",
    "\n",
    "    # 5) RFM + m_credit\n",
    "    'rfm_credit': ['recency', 'f_returning', 'm_price_log', 'f_basket_size']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72884540-5705-4786-98bd-787c187bd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clustering performance\n",
    "res_mm = evaluate_feature_sets(df, dict_features, scaler=MinMaxScaler())\n",
    "res_std = evaluate_feature_sets(df, dict_features, scaler=StandardScaler())\n",
    "res_rob = evaluate_feature_sets(df, dict_features, scaler=RobustScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13d3a9-d4e1-4d62-b913-e3c3f335c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results df\n",
    "df_baseline = pd.concat([res_mm, res_std, res_rob], ignore_index=True)\n",
    "df_baseline.sort_values('silhouette_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a75a67-c88b-47a6-9c07-3d7028cfaacb",
   "metadata": {},
   "source": [
    "#### Recency and Monetary adjustments\n",
    "\n",
    "Comparing recency as a continious and categorical feature with monetary as continious and ratio of installments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bbe16a-e514-4441-8519-525937ca1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da153e86-b703-463e-822c-25aecd517cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_features = {\n",
    "    'rfm_cont_instal': ['recency', 'f_returning', 'm_value_installments', 'f_basket_size', 's_delivery_diff_binary'],\n",
    "\n",
    "    'rfm_cont_log': ['recency', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary'],\n",
    "    \n",
    "    'rfm_flag_instal': ['recent_flag', 'f_returning', 'm_value_installments', 'f_basket_size', 's_delivery_diff_binary'],\n",
    "    \n",
    "    'rfm_flag_log': ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35491c-b06c-480c-a38e-ed58bb65390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clustering performance\n",
    "results_df = evaluate_feature_sets(df, dict_features, scaler=MinMaxScaler())\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874c6d5-d7af-4fae-a9e6-da71a6193957",
   "metadata": {},
   "source": [
    "#### RFMS and other features\n",
    "\n",
    "m_value_installments doesn't seem to clearly differentiate clusters so it's been replaced by m_price_log.\n",
    "\n",
    "Below additional features are added to create more nuanced categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7eaa4-8c24-4d64-9d1a-41863fad32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_features = {\n",
    "    'rfm_1': ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary', 'm_purchasing_power'],\n",
    "\n",
    "    'rfm_2': ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary', 'm_total_installments'],\n",
    "    \n",
    "    'rfm_3': ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary', 'm_credit'],\n",
    "    \n",
    "    'rfm_4': ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary', 'state_spending'],\n",
    "    \n",
    "    'rfm_5': ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary', 'm_pct_freight'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c477328-ad1a-4203-aa60-96fac0596557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clustering performance\n",
    "results_df = evaluate_feature_sets(df, dict_features, scaler=MinMaxScaler())\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683eaad-144b-492d-b627-09d42d09c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar plot\n",
    "features = ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary', 'm_total_installments']\n",
    "\n",
    "X = df[features].values\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(X_scaled)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "dfb = pd.DataFrame(X_scaled, columns=features)\n",
    "dfb['cluster'] = labels\n",
    "\n",
    "profile = dfb.groupby('cluster').mean().round(2)\n",
    "\n",
    "plot_cluster_radar(profile)\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686fa93-406c-4569-8023-09d89cc9a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot\n",
    "fig, axes = plt.subplots(1, len(features), figsize=(len(features)*4, 6), sharey=False)\n",
    "\n",
    "for ax, feature in zip(axes, features):\n",
    "    sns.violinplot(\n",
    "        x='cluster', y=feature,\n",
    "        data=dfb, ax=ax,\n",
    "        inner='quartile', scale='width'\n",
    "    )\n",
    "    ax.set_title(feature)\n",
    "    ax.set_xlabel('Cluster')\n",
    "    ax.set_ylabel(feature)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529decc-4a89-4d25-a5d7-2f4604bd017c",
   "metadata": {},
   "source": [
    "The additional features seem to add noise rather than nuance. We will revert back to the simplified RFMS model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2475c3-0b44-4db7-84ce-43786204b780",
   "metadata": {},
   "source": [
    "### 3.2. DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92369780-2749-4b14-bd4d-78faba113493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont = RobustScaler().fit_transform(df[['m_price_log','f_basket_size']])\n",
    "X_mm   = MinMaxScaler().fit_transform(np.hstack([df[['recent_flag','f_returning','s_delivery_diff_binary']].values, X_cont]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22064462-b351-4a99-bd7f-75d417682bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_install_orders = ['recent_flag', 'f_returning', 'm_price_log', 'f_basket_size', 's_delivery_diff_binary']\n",
    "X = df[rfm_install_orders].values\n",
    "X_scaled = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970bdc2-d297-4cd1-ad38-f416330bbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=5).fit(X_scaled)\n",
    "dists, _ = nbrs.kneighbors(X_scaled)\n",
    "dists = np.sort(dists[:,4])\n",
    "plt.plot(dists)\n",
    "plt.ylabel(\"5th nearest neighbor distance\")\n",
    "plt.xlabel(\"Points sorted by distance\")\n",
    "plt.ylim(0, 0.2)\n",
    "plt.axhline(0.5, linestyle='--', color='red')\n",
    "plt.savefig(f\"./results/5th_nearest_neighbor_distance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c255d6-729d-431c-8a46-4c4d4b7065df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN clustering\n",
    "eps_values        = [0.01, 0.05, 0.15, 0.20]\n",
    "min_samples_vals  = [5, 10, 50]\n",
    "\n",
    "results = []\n",
    "for eps in eps_values:\n",
    "    for ms in min_samples_vals:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms).fit(X_scaled)\n",
    "        labels = db.labels_\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise    = (labels == -1).sum()\n",
    "        sil = silhouette_score(X_scaled[labels != -1], labels[labels != -1])\n",
    "\n",
    "        results.append({\n",
    "            'eps':            eps,\n",
    "            'min_samples':    ms,\n",
    "            'n_clusters':     n_clusters,\n",
    "            'n_noise':        n_noise,\n",
    "            'silhouette':     sil\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.sort_values(['silhouette','n_clusters'], ascending=[False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d425c-38de-4e39-8fad-9bc748a3ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN clustering\n",
    "db = DBSCAN(eps=0.2, min_samples=50).fit(X_scaled)\n",
    "labels_db = db.labels_\n",
    "n_db = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "print(f\"DBSCAN found {n_db} clusters (and {(labels_db==-1).sum()} noise points)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fb7eb-1159-421e-9ecb-f692a9fa13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette score for DBSCAN\n",
    "print(\"Silhouette:\", silhouette_score(X_scaled[labels_db!=-1], labels_db[labels_db!=-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14477374-2e68-468b-9e86-879d75f03cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations per cluster\n",
    "unique, counts = np.unique(labels_db, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbbb20-6e2e-448d-a570-a9eebe1c4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar plot\n",
    "df_db = pd.DataFrame(X_scaled, columns=rfm_install_orders)\n",
    "df_db['cluster'] = labels_db\n",
    "profile = df_db[df_db['cluster'] != -1].groupby('cluster').mean()\n",
    "plot_cluster_radar(profile)\n",
    "profile.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb6252-c2da-4dd3-a931-e42a293ff88a",
   "metadata": {},
   "source": [
    "## 4. Best combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75f878-5e91-4ceb-a717-24a37c9f1396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Radar plot\n",
    "features = ['recent_flag', 'f_returning', 'm_price_log', 's_delivery_diff_binary']\n",
    "\n",
    "X = df[features].values\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(X_scaled)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "dfb = pd.DataFrame(X_scaled, columns=features)\n",
    "dfb['cluster'] = labels\n",
    "\n",
    "profile = dfb.groupby('cluster').mean().round(2)\n",
    "\n",
    "plot_cluster_radar(profile)\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b7f95-8f95-425f-b2ff-40a0c675b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot\n",
    "fig, axes = plt.subplots(1, len(features), figsize=(len(features)*4, 6), sharey=False)\n",
    "\n",
    "for ax, feature in zip(axes, features):\n",
    "    sns.violinplot(\n",
    "        x='cluster', y=feature,\n",
    "        data=dfb, ax=ax,\n",
    "        inner='quartile', scale='width'\n",
    "    )\n",
    "    ax.set_title(feature)\n",
    "    ax.set_xlabel('Cluster')\n",
    "    ax.set_ylabel(feature)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d17d5-c10e-4439-b647-1f680078c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clusters\n",
    "best_k, fig = evaluate_clusters(\n",
    "    data=df,\n",
    "    feature_cols=['recent_flag', 'f_returning', 'm_price_log', 's_delivery_diff_binary'],\n",
    "    metric=\"distortion\",\n",
    "    k_min=2,\n",
    "    k_max=10\n",
    ")\n",
    "\n",
    "print(\"Optimal number of clusters according to the elbow for RFMR:\", best_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
